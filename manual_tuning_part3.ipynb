{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual tuning the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we manually tune our hyper-parmeters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take the previous steps again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#importing the  necessary modules\n",
    "import pandas                                      #to read and manipulate data\n",
    "import zipfile                                     #to extract data\n",
    "import numpy as np                                 #for matrix operations\n",
    "#rest will be imported as and when required\n",
    "#read the train and test zip file\n",
    "zip_ref = zipfile.ZipFile(\"train.csv.zip\", 'r')    \n",
    "zip_ref.extractall()                               \n",
    "zip_ref.close()\n",
    "\n",
    "train_data = pandas.read_csv(\"train.csv\")\n",
    "\n",
    "import copy\n",
    "test_data = copy.deepcopy(train_data.iloc[150000:])\n",
    "train_data = train_data.iloc[:150000]\n",
    "\n",
    "y_true = test_data['loss']\n",
    "\n",
    "ids = test_data['id']\n",
    "\n",
    "target = train_data['loss']\n",
    "\n",
    "#drop the unnecessary column id and loss from both train and test set.\n",
    "train_data.drop(['id','loss'],1,inplace=True)\n",
    "test_data.drop(['id','loss'],1,inplace=True)\n",
    "\n",
    "shift = 200\n",
    "target = np.log(target+shift)\n",
    "\n",
    "#merging both the datasets to make single joined dataset\n",
    "joined = pandas.concat([train_data, test_data],ignore_index = True)\n",
    "del train_data,test_data                                         #deleting previous one to save memory.\n",
    "\n",
    "cat_feature = [n for n in joined.columns if n.startswith('cat')]  #list of all the features containing categorical values\n",
    "\n",
    "#factorizing them\n",
    "for column in cat_feature:\n",
    "    joined[column] = pandas.factorize(joined[column].values, sort=True)[0]\n",
    "        \n",
    "del cat_feature\n",
    "\n",
    "#dividing the training data between training and testing set\n",
    "train_data = joined.iloc[:150000,:]\n",
    "test_data = joined.iloc[150000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demonicode/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we vary max_depth in (10,12,14) and min_child_weight in (1,3,5,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE - Since i ran it on cloud, i'm going to post the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 2016\n",
    "params = {\n",
    "        'min_child_weight': 1,\n",
    "        'eta': 0.1,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'alpha': 1,\n",
    "        'gamma': 0,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': RANDOM_STATE,'eval_metric': 'mae','verbose_eval': 2,\n",
    "}\n",
    "\n",
    "\n",
    "max_depth_list = [10,12,14]\n",
    "min_child_weight_list = [1,3,5,7]\n",
    "num_rounds = 3000\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_data, label=target)\n",
    "xgtest = xgb.DMatrix(test_data)\n",
    "maxima = 100000\n",
    "for maxdep in max_depth_list:\n",
    "    for minchild in min_child_weight_list:\n",
    "        params['max_depth'] = maxdep\n",
    "        params['min_child_weight']=minchild\n",
    "        \n",
    "        cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,seed=RANDOM_STATE,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "        if (cv_result['test-mae-mean'].values[-1] <maxima ):\n",
    "            maxima = cv_result['test-mae-mean'].values[-1]\n",
    "            bestmaxdep = maxdep\n",
    "            bestminchild = minchild\n",
    "        print (maxdep,'     ',minchild,\"     \",cv_result['test-mae-mean'].values[-1])\n",
    "\n",
    "print (bestmaxdep,\"           \",bestminchild)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[139]   train-mae:0.305661+0.000602291  test-mae:0.375355+0.00211668\n",
    "\n",
    "10       1       0.3753548\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[143]   train-mae:0.306291+0.00100258   test-mae:0.375034+0.00233107\n",
    "\n",
    "10       3       0.375034\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[152]   train-mae:0.306287+0.000609339  test-mae:0.37527+0.00213009\n",
    "\n",
    "10       5       0.37527\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[147]   train-mae:0.310621+0.00130089   test-mae:0.37492+0.00237081\n",
    "\n",
    "10       7       0.3749202\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[97]    train-mae:0.29218+0.00148319    test-mae:0.376971+0.00225105\n",
    "\n",
    "12       1       0.3769712\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[96]    train-mae:0.295886+0.0011533    test-mae:0.376657+0.00194915\n",
    "\n",
    "12       3       0.3766568\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[116]   train-mae:0.286386+0.00210224   test-mae:0.37634+0.0023462\n",
    "\n",
    "12       5       0.3763404\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[108]   train-mae:0.295717+0.00118999   test-mae:0.375984+0.00233127\n",
    "\n",
    "12       7       0.375984\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[81]    train-mae:0.272055+0.00186085   test-mae:0.378714+0.00215556\n",
    "\n",
    "14       1       0.378714\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[88]    train-mae:0.269372+0.00176924   test-mae:0.378405+0.0023122\n",
    "\n",
    "14       3       0.378405\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[89]    train-mae:0.273725+0.00172026   test-mae:0.378082+0.00237633\n",
    "\n",
    "14       5       0.3780822\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[89]    train-mae:0.279501+0.00160486   test-mae:0.377553+0.00209547\n",
    "\n",
    "14       7       0.3775534\n",
    "10             7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives values as max_depth = 10 and min_child_weight = 7. Since both are border cases, we need to check for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we check for max_depth in (4,5,6,7,8,9,10,11) and min_child_weight in (6,7,8,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE- I ran it different ties, like at first for max_depth = 7,8,9 and then max_depth = 5,6,7 etc.However, for the sake of simplicity and not wanting to make this file longer than required i have combined the results in a single file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_depth_list = [4,5,6,7,8,9,10,11]\n",
    "min_child_weight_list = [6,7,8,9]\n",
    "num_rounds = 3000\n",
    "\n",
    "maxima = 100000\n",
    "for maxdep in max_depth_list:\n",
    "    for minchild in min_child_weight_list:\n",
    "        params['max_depth'] = maxdep\n",
    "        params['min_child_weight']=minchild\n",
    "        \n",
    "        cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,seed=RANDOM_STATE,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "        if (cv_result['test-mae-mean'].values[-1] <maxima ):\n",
    "            maxima = cv_result['test-mae-mean'].values[-1]\n",
    "            bestmaxdep = maxdep\n",
    "            bestminchild = minchild\n",
    "        print (maxdep,'     ',minchild,\"     \",cv_result['test-mae-mean'].values[-1])\n",
    "\n",
    "print (bestmaxdep,\"           \",bestminchild)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[164]   train-mae:0.321954+0.000704801  test-mae:0.374467+0.0024976\n",
    "\n",
    "9       6       0.3744668\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[177]   train-mae:0.318851+0.000738684  test-mae:0.374326+0.00206189\n",
    "\n",
    "9       7       0.3743256\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[167]   train-mae:0.32266+0.000860636   test-mae:0.374206+0.00244208\n",
    "\n",
    "9       8       0.3742058\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[145]   train-mae:0.310124+0.000485493  test-mae:0.374526+0.0022774\n",
    "\n",
    "10       6       0.3745256\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[147]   train-mae:0.310621+0.00130089   test-mae:0.37492+0.00237081\n",
    "\n",
    "10       7       0.3749202\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[135]   train-mae:0.316236+0.00060147   test-mae:0.374908+0.00228443\n",
    "\n",
    "10       8       0.3749078\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[125]   train-mae:0.301198+0.00131219   test-mae:0.375223+0.00218619\n",
    "\n",
    "11       6       0.3752226\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[112]   train-mae:0.309151+0.000777521  test-mae:0.375414+0.00236391\n",
    "\n",
    "11       7       0.375414\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[124]   train-mae:0.304937+0.001528     test-mae:0.375329+0.00211841\n",
    "\n",
    "11       8       0.3753294\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[208]   train-mae:0.329836+0.000550497  test-mae:0.373912+0.00223101\n",
    "\n",
    "8       8       0.3739124\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[219]   train-mae:0.328465+0.00101536   test-mae:0.373974+0.00246124\n",
    "\n",
    "8       9       0.3739736\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[167]   train-mae:0.32266+0.000860636   test-mae:0.374206+0.00244208\n",
    "\n",
    "9       8       0.3742058\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[187]   train-mae:0.318274+0.00108897   test-mae:0.374366+0.00218189\n",
    "\n",
    "9       9       0.374366\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[455]   train-mae:0.338124+0.000571235  test-mae:0.373179+0.002213\n",
    "\n",
    "6       8       0.3731788\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[318]   train-mae:0.331869+0.000525003  test-mae:0.373462+0.00235517\n",
    "\n",
    "7       8       0.373462\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[208]   train-mae:0.329836+0.000550497  test-mae:0.373912+0.00223101\n",
    "\n",
    "8       8       0.3739124\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[1209]  train-mae:0.349333+0.000581018  test-mae:0.37333+0.0024643\n",
    "\n",
    "4       8       0.37333\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[636]   train-mae:0.346278+0.000684862  test-mae:0.37333+0.00236586\n",
    "\n",
    "5       8       0.3733298\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[455]   train-mae:0.338124+0.000571235  test-mae:0.373179+0.002213\n",
    "\n",
    "6       8       0.3731788\n",
    "6             8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, we get the best value of max_depth = 8 and min_child_weight = 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Gamma now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set the values of max_depth and min_child_weight and vary gamma in (0.0,0.1,0.2,0.5,0.8,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 6\n",
    "params['min_child_weight']=8\n",
    "\n",
    "gamma_list = [0.0,0.1,0.2,0.3,0.4]\n",
    "\n",
    "num_rounds = 3000\n",
    "\n",
    "maxima = 100000\n",
    "\n",
    "for gamma_val in gamma_list:\n",
    "    params['gamma'] = gamma_val\n",
    "    cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,seed=RANDOM_STATE,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "    if (cv_result['test-mae-mean'].values[-1] <maxima ):\n",
    "        maxima = cv_result['test-mae-mean'].values[-1]\n",
    "        bestgamma = gamma_val\n",
    "            \n",
    "    print ('gamma:','     ',gamma_val,\"     \",cv_result['test-mae-mean'].values[-1])\n",
    "\n",
    "print ('best gamma value:',bestgamma)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[455]   train-mae:0.338124+0.000571235  test-mae:0.373179+0.002213\n",
    "\n",
    "gamma:       0.0       0.3731788\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[436]   train-mae:0.339544+0.000723601  test-mae:0.3733+0.00223398\n",
    "\n",
    "gamma:       0.1       0.3732996\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[423]   train-mae:0.340471+0.000908664  test-mae:0.373372+0.00240319\n",
    "\n",
    "gamma:       0.2       0.3733716\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "gamma:       0.5       0.3742252\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[216]   train-mae:0.325474+0.000335294  test-mae:0.373722+0.00229901\n",
    "\n",
    "gamma:       0.8       0.3737216\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[247]   train-mae:0.328166+0.000673034  test-mae:0.373512+0.00216634\n",
    "\n",
    "gamma:       1.0       0.3735116\n",
    "best gamma value:0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The best value for gamma is 0.0 only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning col_sample_list and subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set the values of max_depth and min_child_weight and vary col_sample in (0.0,0.1,0.2,0.5,0.8,1.0) and subsample in ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['gamma'] = 0.0\n",
    "\n",
    "col_sample_list = [0.3,0.5,0.7,0.9]\n",
    "subsample_list = [0.3,0.5,0.7,0.9]\n",
    "\n",
    "num_rounds = 3000\n",
    "\n",
    "maxima = 100000\n",
    "\n",
    "for colsample in col_sample_list:\n",
    "    for subsample in subsample_list:\n",
    "        params['colsample_bytree'] = colsample\n",
    "        params['subsample'] = subsample\n",
    "        \n",
    "        cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,seed=RANDOM_STATE,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "        if (cv_result['test-mae-mean'].values[-1] <maxima ):\n",
    "            maxima = cv_result['test-mae-mean'].values[-1]\n",
    "            bestcol = colsample\n",
    "            bestsub = subsample\n",
    "        print (\"colsample:\",colsample,'     ',\"subsample:\",subsample,\"     \",cv_result['test-mae-mean'].values[-1])\n",
    "\n",
    "print (\"col:\",bestcol,\"           \",\"sub:\",bestsub)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[164]   train-mae:0.347278+0.000960707  test-mae:0.377889+0.00267434\n",
    "\n",
    "colsample: 0.3       subsample: 0.3       0.3778888\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[171]   train-mae:0.338302+0.00104506   test-mae:0.375754+0.0023155\n",
    "\n",
    "colsample: 0.3       subsample: 0.5       0.3757536\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[231]   train-mae:0.322145+0.0010546    test-mae:0.37438+0.00231949\n",
    "\n",
    "colsample: 0.3       subsample: 0.7       0.3743798\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[256]   train-mae:0.314295+0.00159014   test-mae:0.373813+0.0023904\n",
    "\n",
    "colsample: 0.3       subsample: 0.9       0.3738134\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[150]   train-mae:0.345739+0.00091591   test-mae:0.378218+0.00240492\n",
    "\n",
    "colsample: 0.5       subsample: 0.3       0.3782176\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[177]   train-mae:0.332512+0.00126407   test-mae:0.375932+0.0023026\n",
    "\n",
    "colsample: 0.5       subsample: 0.5       0.3759318\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[197]   train-mae:0.322158+0.00103509   test-mae:0.374547+0.00268987\n",
    "\n",
    "colsample: 0.5       subsample: 0.7       0.3745468\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[212]   train-mae:0.316006+0.00139258   test-mae:0.373787+0.00245819\n",
    "\n",
    "colsample: 0.5       subsample: 0.9       0.3737872\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[134]   train-mae:0.346648+0.0006778    test-mae:0.377686+0.00208084\n",
    "\n",
    "colsample: 0.7       subsample: 0.3       0.3776862\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[154]   train-mae:0.334538+0.00131568   test-mae:0.376049+0.00240811\n",
    "\n",
    "colsample: 0.7       subsample: 0.5       0.3760494\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[176]   train-mae:0.322974+0.00108391   test-mae:0.375085+0.00221452\n",
    "\n",
    "colsample: 0.7       subsample: 0.7       0.3750854\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[214]   train-mae:0.311863+0.00169539   test-mae:0.373921+0.00210249\n",
    "\n",
    "colsample: 0.7       subsample: 0.9       0.373921\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[127]   train-mae:0.3473+0.00080458     test-mae:0.378046+0.00220266\n",
    "\n",
    "colsample: 0.9       subsample: 0.3       0.3780464\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[143]   train-mae:0.33548+0.000711149   test-mae:0.376282+0.00216247\n",
    "\n",
    "colsample: 0.9       subsample: 0.5       0.3762824\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[161]   train-mae:0.32416+0.00022592    test-mae:0.37486+0.00259281\n",
    "\n",
    "colsample: 0.9       subsample: 0.7       0.3748602\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[185]   train-mae:0.315528+0.00156167   test-mae:0.374016+0.00211127\n",
    "\n",
    "colsample: 0.9       subsample: 0.9       0.3740164\n",
    "col: 0.5             sub: 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The best values obtained are col_sample = 0.5 and sub_sample = 0.9. Next, we try to values in a gap of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_sample_list = [0.45,0.50,0.55]\n",
    "subsample_list = [0.85,0.90,0.95,1.0]\n",
    "\n",
    "num_rounds = 3000\n",
    "\n",
    "maxima = 100000\n",
    "\n",
    "for colsample in col_sample_list:\n",
    "    for subsample in subsample_list:\n",
    "        params['colsample_bytree'] = colsample\n",
    "        params['subsample'] = subsample\n",
    "        \n",
    "        cv_result = xgb.cv(params, xgtrain, num_boost_round=num_rounds, nfold=5,seed=RANDOM_STATE,\n",
    "             callbacks=[xgb.callback.early_stop(50)])\n",
    "        if (cv_result['test-mae-mean'].values[-1] <maxima ):\n",
    "            maxima = cv_result['test-mae-mean'].values[-1]\n",
    "            bestcol = colsample\n",
    "            bestsub = subsample\n",
    "        print (\"colsample:\",colsample,'     ',\"subsample:\",subsample,\"     \",cv_result['test-mae-mean'].values[-1])\n",
    "\n",
    "print (\"col:\",bestcol,\"           \",\"sub:\",bestsub)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[544]   train-mae:0.336931+0.000884705  test-mae:0.373095+0.00243941\n",
    "\n",
    "colsample: 0.45       subsample: 0.85       0.3730954\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[616]   train-mae:0.333108+0.000826946  test-mae:0.372965+0.00238837\n",
    "\n",
    "colsample: 0.45       subsample: 0.9       0.3729654\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[575]   train-mae:0.335237+0.000721526  test-mae:0.372755+0.00225287\n",
    "\n",
    "colsample: 0.45       subsample: 0.95       0.3727552\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[595]   train-mae:0.333348+0.000853109  test-mae:0.372932+0.00253045\n",
    "\n",
    "colsample: 0.5       subsample: 0.85       0.3729324\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[520]   train-mae:0.33733+0.000913062   test-mae:0.372937+0.00251501\n",
    "\n",
    "colsample: 0.5       subsample: 0.9       0.372937\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[579]   train-mae:0.333952+0.000691618  test-mae:0.372993+0.00248749\n",
    "\n",
    "colsample: 0.5       subsample: 0.95       0.3729932\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[490]   train-mae:0.337011+0.000677289  test-mae:0.373275+0.0023786\n",
    "\n",
    "colsample: 0.65       subsample: 0.85       0.3732746\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[504]   train-mae:0.336404+0.000656293  test-mae:0.373148+0.00254256\n",
    "\n",
    "colsample: 0.65       subsample: 0.9       0.3731478\n",
    "Multiple eval metrics have been passed: 'test-mae' will be used for early stopping.\n",
    "\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[519]   train-mae:0.335617+0.00101215   test-mae:0.372786+0.0022168\n",
    "\n",
    "colsample: 0.65       subsample: 0.95       0.3727858\n",
    "Will train until test-mae hasn't improved in 50 rounds.\n",
    "Stopping. Best iteration:\n",
    "[558]   train-mae:0.336056+0.000652872  test-mae:0.372712+0.00243462\n",
    "\n",
    "colsample: 0.45       subsample: 1.0       0.3727118\n",
    "col: 0.45             sub: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best values obtained are col_sample = 0.45 and sub_sample = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We don't need to tune alpha as most of the regularization is provided by gamma itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's lower the learning rate now to 0.01 and use these values in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Tuned_XGBoost_part4.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
