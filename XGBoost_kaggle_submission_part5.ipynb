{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last part, we use the final tuned model to finally see the Kaggle score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the data again "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the prepprocessing of the data as done on the previous part. However, instead of dividing the train data, we will use the test data provided by Kaggle this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#importing the  necessary modules\n",
    "import pandas\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import zipfile\n",
    "from sklearn import cross_validation, metrics\n",
    "\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"train.csv.zip\", 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n",
    "\n",
    "#loading train data to be used to create submission file to submission file to be used for kaggle submission\n",
    "zip_ref2 = zipfile.ZipFile(\"test.csv.zip\", 'r')\n",
    "zip_ref2.extractall()\n",
    "zip_ref2.close()\n",
    "\n",
    "\n",
    "train_data = pandas.read_csv(\"train.csv\")\n",
    "test_data = pandas.read_csv(\"test.csv\")\n",
    "ids = test_data['id']\n",
    "test_data['loss'] = np.nan\n",
    "\n",
    "\n",
    "joined = pandas.concat([train_data, test_data],ignore_index = True)\n",
    "del train_data,test_data\n",
    "\n",
    "cat_feature = [n for n in joined.columns if n.startswith('cat')]\n",
    "\n",
    "for column in cat_feature:\n",
    "        joined[column] = pandas.factorize(joined[column].values, sort=True)[0]\n",
    "        \n",
    "del cat_feature\n",
    "\n",
    "\n",
    "\n",
    "train_data = joined[joined['loss'].notnull()]\n",
    "test_data = joined[joined['loss'].isnull()]\n",
    "del joined\n",
    "\n",
    "shift = 200\n",
    "train_data[\"loss\"] = np.log(train_data[\"loss\"]+shift)\n",
    "target = train_data['loss']\n",
    "train_data.drop(['id','loss'],1,inplace=True)\n",
    "test_data.drop(['id','loss'],1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2016\n",
    "params = {\n",
    "        'min_child_weight': 8,\n",
    "        'eta': 0.01,\n",
    "        'colsample_bytree': 0.45,\n",
    "        'max_depth': 6,\n",
    "        'subsample': 1.0,\n",
    "        'alpha': 1,\n",
    "        'gamma': 0,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': RANDOM_STATE,'verbose_eval': 2}\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_data, label=target)\n",
    "xgtest = xgb.DMatrix(test_data)\n",
    "\n",
    "model = xgb.train(params, xgtrain, 3000, feval=evalerror)\n",
    "\n",
    "prediction = np.exp(model.predict(xgtest)) - shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, making a submission file for Kaggle servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pandas.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After submitting the Kaggle file, the score recieved was 1122.14212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
