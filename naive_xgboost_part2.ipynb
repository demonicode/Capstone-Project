{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a basic xgboost model without fine tuning it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, doing the necessary steps like preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#importing the  necessary modules\n",
    "import pandas                                      #to read and manipulate data\n",
    "import zipfile                                     #to extract data\n",
    "import numpy as np                                 #for matrix operations\n",
    "#rest will be imported as and when required\n",
    "#read the train and test zip file\n",
    "zip_ref = zipfile.ZipFile(\"train.csv.zip\", 'r')    \n",
    "zip_ref.extractall()                               \n",
    "zip_ref.close()\n",
    "\n",
    "train_data = pandas.read_csv(\"train.csv\")\n",
    "\n",
    "import copy\n",
    "test_data = copy.deepcopy(train_data.iloc[150000:])\n",
    "train_data = train_data.iloc[:150000]\n",
    "\n",
    "y_true = test_data['loss']\n",
    "\n",
    "ids = test_data['id']\n",
    "\n",
    "target = train_data['loss']\n",
    "\n",
    "#drop the unnecessary column id and loss from both train and test set.\n",
    "train_data.drop(['id','loss'],1,inplace=True)\n",
    "test_data.drop(['id','loss'],1,inplace=True)\n",
    "\n",
    "shift = 200\n",
    "target = np.log(target+shift)\n",
    "\n",
    "#merging both the datasets to make single joined dataset\n",
    "joined = pandas.concat([train_data, test_data],ignore_index = True)\n",
    "del train_data,test_data                                         #deleting previous one to save memory.\n",
    "\n",
    "cat_feature = [n for n in joined.columns if n.startswith('cat')]  #list of all the features containing categorical values\n",
    "\n",
    "#factorizing them\n",
    "for column in cat_feature:\n",
    "    joined[column] = pandas.factorize(joined[column].values, sort=True)[0]\n",
    "        \n",
    "del cat_feature\n",
    "\n",
    "#dividing the training data between training and testing set\n",
    "train_data = joined.iloc[:150000,:]\n",
    "test_data = joined.iloc[150000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we import the model and the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demonicode/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the default parameters as given in this link - https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2016\n",
    "params = {\n",
    "        'min_child_weight': 1,\n",
    "        'eta': 0.1,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'alpha': 1,\n",
    "        'gamma': 0,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': RANDOM_STATE,'eval_metric': 'mae','verbose_eval': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_data, label=target)                   #training matrix\n",
    "xgtest = xgb.DMatrix(test_data)                                   #testing matrix\n",
    "model = xgb.train(params, xgtrain, 3000, feval=evalerror)         \n",
    "#3000 is taken intuitely(after seeing the iterations during finetuning)\n",
    "prediction = np.exp(model.predict(xgtest)) - shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153.07151852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "error = mean_absolute_error(y_true,prediction)\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive XGBoost model gives an score of 1153.07151852. Its time to fine tune it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Open manual_tuning.ipynb "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
